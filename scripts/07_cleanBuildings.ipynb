{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Buildings Data\n",
    "This script cleans the buildings data which was downloaded from https://smart-zwolle.opendata.arcgis.com/datasets/digitale-tweelingstad-zwolle-adressen-2d/about\n",
    "\n",
    "The column names are as follows:\n",
    "['IDENTIFICA', 'ADRES', 'POSTCODE', 'STATUS', 'GEBRUIKSDO', 'OPPERVLAKT', 'PAND_IDENT', 'BOUWJAAR', 'ACTIVITEIT', 'WOZ_ONDERD', 'BUURTNAAM', 'WIJKNAAM', 'GEMEENTE', 'VEILIGHEID', 'WATERSCHAP', 'NETBEHEERD', 'DRINKWATER', 'NAAM', 'MONUMENT', 'LRK', 'KVK', 'LEEFBAARHE', 'GEBOUWTYPE', 'GEBOUWSUBT', 'ENERGIELAB', 'BEREKENING', 'AANDEELHER', 'ENERGIEBEH', 'GRONDHOOGT', 'HOOGTE', 'BOUWLAAG_G', 'BOUWLAAG', 'GASVERBRUI', 'ELECTRAVER', 'DAKVORM', 'DAKVORM_LA', 'ZONNEPANEL', 'BEREIKBAAR', 'BEREIKBA_1', 'BVB_LI', 'BVB_VI', 'BVB_FI', 'BVB_SI', 'IS_BIJEENK', 'IS_GEZONDH', 'IS_INDUSTR', 'IS_KANTOOR', 'IS_LOGIES', 'IS_ONDERWI', 'IS_SPORT', 'IS_WINKEL', 'IS_WOON', 'IS_KAS', 'geometry']\n",
    "\n",
    "Processing and output:\n",
    "\n",
    "The file was saved as a shapefile and used in the script below. \n",
    "\n",
    "## Before running:\n",
    "1. Update directories and file names as necessary under CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processing shapefile: ../raw_data/Digitale_Tweelingstad_Zwolle_Adressen_2D.shp\n",
      "üßæ Standardized column names:\n",
      "  - 'IDENTIFICA' ‚ûú 'identifica'\n",
      "  - 'ADRES' ‚ûú 'adres'\n",
      "  - 'POSTCODE' ‚ûú 'postcode'\n",
      "  - 'STATUS' ‚ûú 'status'\n",
      "  - 'GEBRUIKSDO' ‚ûú 'gebruiksdo'\n",
      "  - 'OPPERVLAKT' ‚ûú 'oppervlakt'\n",
      "  - 'PAND_IDENT' ‚ûú 'pand_ident'\n",
      "  - 'BOUWJAAR' ‚ûú 'bouwjaar'\n",
      "  - 'ACTIVITEIT' ‚ûú 'activiteit'\n",
      "  - 'WOZ_ONDERD' ‚ûú 'woz_onderd'\n",
      "  - 'BUURTNAAM' ‚ûú 'buurt_naam'\n",
      "  - 'WIJKNAAM' ‚ûú 'wijk_naam'\n",
      "  - 'GEMEENTE' ‚ûú 'gemeente'\n",
      "  - 'VEILIGHEID' ‚ûú 'veiligheid'\n",
      "  - 'WATERSCHAP' ‚ûú 'waterschap'\n",
      "  - 'NETBEHEERD' ‚ûú 'netbeheerd'\n",
      "  - 'DRINKWATER' ‚ûú 'drinkwater'\n",
      "  - 'NAAM' ‚ûú 'naam'\n",
      "  - 'MONUMENT' ‚ûú 'monument'\n",
      "  - 'LRK' ‚ûú 'lrk'\n",
      "  - 'KVK' ‚ûú 'kvk'\n",
      "  - 'LEEFBAARHE' ‚ûú 'leefbaarhe'\n",
      "  - 'GEBOUWTYPE' ‚ûú 'gebouwtype'\n",
      "  - 'GEBOUWSUBT' ‚ûú 'gebouwsubt'\n",
      "  - 'ENERGIELAB' ‚ûú 'energielab'\n",
      "  - 'BEREKENING' ‚ûú 'berekening'\n",
      "  - 'AANDEELHER' ‚ûú 'aandeelher'\n",
      "  - 'ENERGIEBEH' ‚ûú 'energiebeh'\n",
      "  - 'GRONDHOOGT' ‚ûú 'grondhoogt'\n",
      "  - 'HOOGTE' ‚ûú 'hoogte'\n",
      "  - 'BOUWLAAG_G' ‚ûú 'bouwlaag_g'\n",
      "  - 'BOUWLAAG' ‚ûú 'bouwlaag'\n",
      "  - 'GASVERBRUI' ‚ûú 'gasverbrui'\n",
      "  - 'ELECTRAVER' ‚ûú 'electraver'\n",
      "  - 'DAKVORM' ‚ûú 'dakvorm'\n",
      "  - 'DAKVORM_LA' ‚ûú 'dakvorm_la'\n",
      "  - 'ZONNEPANEL' ‚ûú 'zonnepanel'\n",
      "  - 'BEREIKBAAR' ‚ûú 'bereikbaar'\n",
      "  - 'BEREIKBA_1' ‚ûú 'bereikba_1'\n",
      "  - 'BVB_LI' ‚ûú 'bvb_li'\n",
      "  - 'BVB_VI' ‚ûú 'bvb_vi'\n",
      "  - 'BVB_FI' ‚ûú 'bvb_fi'\n",
      "  - 'BVB_SI' ‚ûú 'bvb_si'\n",
      "  - 'IS_BIJEENK' ‚ûú 'is_bijeenk'\n",
      "  - 'IS_GEZONDH' ‚ûú 'is_gezondh'\n",
      "  - 'IS_INDUSTR' ‚ûú 'is_industr'\n",
      "  - 'IS_KANTOOR' ‚ûú 'is_kantoor'\n",
      "  - 'IS_LOGIES' ‚ûú 'is_logies'\n",
      "  - 'IS_ONDERWI' ‚ûú 'is_onderwi'\n",
      "  - 'IS_SPORT' ‚ûú 'is_sport'\n",
      "  - 'IS_WINKEL' ‚ûú 'is_winkel'\n",
      "  - 'IS_WOON' ‚ûú 'is_woon'\n",
      "  - 'IS_KAS' ‚ûú 'is_kas'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_21836\\145773073.py:55: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total rows after cleaning: 71888\n",
      "üìå Unique neighborhoods: 78\n",
      "buurt_naam\n",
      "milligen                             2977\n",
      "frankhuis                            2411\n",
      "oud-assendorp                        2361\n",
      "aa-landen-midden                     2355\n",
      "hogenkamp                            2318\n",
      "                                     ... \n",
      "langenholte                            56\n",
      "bedrijventerrein voorst-d              30\n",
      "stadsbroek                             28\n",
      "bedrijventerrein marslanden-noord      24\n",
      "mastenbroek                            23\n",
      "Name: count, Length: 78, dtype: int64\n",
      "üìç Unique districts: 16\n",
      "wijk_naam\n",
      "stadshagen               11924\n",
      "assendorp                 7771\n",
      "diezerpoort               7600\n",
      "aa-landen                 6893\n",
      "ittersum                  6739\n",
      "schelle                   6328\n",
      "holtenbroek               6091\n",
      "binnenstad                3961\n",
      "wipstrik                  3449\n",
      "berkum                    2997\n",
      "westenholte               2600\n",
      "kamperpoort-veerallee     2263\n",
      "marsweteringlanden        2045\n",
      "vechtlanden                496\n",
      "poort van zwolle           388\n",
      "soestweteringlanden        343\n",
      "Name: count, dtype: int64\n",
      "üìÅ Saved cleaned shapefile to: ../clean_data/Digitale_Tweelingstad_Zwolle_Adressen_2D_cleaned.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "RAW_DATA_DIR = \"../raw_data/\"\n",
    "OUTPUT_DIR = \"../clean_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "shapefile_path = os.path.join(RAW_DATA_DIR, \"Digitale_Tweelingstad_Zwolle_Adressen_2D.shp\")\n",
    "output_shapefile_path = os.path.join(OUTPUT_DIR, \"Digitale_Tweelingstad_Zwolle_Adressen_2D_cleaned.shp\")\n",
    "\n",
    "# Aliases to unify inconsistent column names\n",
    "COLUMN_ALIASES = {\n",
    "    \"buurtname\": \"buurt_naam\",\n",
    "    \"buurtnaam\": \"buurt_naam\",\n",
    "    \"buurt\": \"buurt_naam\",\n",
    "    \"wijknaam\": \"wijk_naam\",\n",
    "    \"wijk\": \"wijk_naam\",\n",
    "}\n",
    "\n",
    "# -------------------------------\n",
    "# FUNCTIONS\n",
    "# -------------------------------\n",
    "def normalize_name(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    name = str(name).strip().lower()\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    name = name.replace(\".\", \"\")\n",
    "    return name\n",
    "\n",
    "def clean_column_names(df):\n",
    "    def clean(col):\n",
    "        col = re.sub(r\"\\[.*?\\]|\\(.*?\\)\", \"\", col)\n",
    "        col = col.strip().lower()\n",
    "        col = re.sub(r\"[^\\w\\s]\", \"\", col)\n",
    "        col = re.sub(r\"\\s+\", \"_\", col)\n",
    "        col = re.sub(r\"_+\", \"_\", col)\n",
    "        col = col.strip(\"_\")\n",
    "        col = COLUMN_ALIASES.get(col, col)\n",
    "        return col\n",
    "    original_columns = df.columns.tolist()\n",
    "    df.columns = [clean(col) for col in df.columns]\n",
    "    print(\"üßæ Standardized column names:\")\n",
    "    for old, new in zip(original_columns, df.columns):\n",
    "        if old != new:\n",
    "            print(f\"  - '{old}' ‚ûú '{new}'\")\n",
    "    return df\n",
    "\n",
    "def strip_whitespace(df):\n",
    "    return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "def clean_data(df):\n",
    "    df = strip_whitespace(df)\n",
    "    df = df.dropna(how='all')\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# PROCESSING SHAPEFILE\n",
    "# -------------------------------\n",
    "print(f\"\\nüîÑ Processing shapefile: {shapefile_path}\")\n",
    "try:\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    gdf = clean_column_names(gdf)\n",
    "\n",
    "    # Normalize buurt_naam and wijk_naam\n",
    "    if \"buurt_naam\" in gdf.columns:\n",
    "        gdf[\"buurt_naam\"] = gdf[\"buurt_naam\"].apply(normalize_name)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è 'buurt_naam' column not found.\")\n",
    "\n",
    "    if \"wijk_naam\" in gdf.columns:\n",
    "        gdf[\"wijk_naam\"] = gdf[\"wijk_naam\"].apply(normalize_name)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è 'wijk_naam' column not found.\")\n",
    "\n",
    "    gdf = clean_data(gdf)\n",
    "\n",
    "    print(f\"‚úÖ Total rows after cleaning: {len(gdf)}\")\n",
    "    \n",
    "    if \"buurt_naam\" in gdf.columns:\n",
    "        print(f\"üìå Unique neighborhoods: {gdf['buurt_naam'].nunique()}\")\n",
    "        print(gdf['buurt_naam'].value_counts())\n",
    "\n",
    "    if \"wijk_naam\" in gdf.columns:\n",
    "        print(f\"üìç Unique districts: {gdf['wijk_naam'].nunique()}\")\n",
    "        print(gdf['wijk_naam'].value_counts())\n",
    "\n",
    "    gdf.to_file(output_shapefile_path)\n",
    "    print(f\"üìÅ Saved cleaned shapefile to: {output_shapefile_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to process shapefile: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimize Data\n",
    "\n",
    "This process selects columns that will be used for future modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Processing shapefile: ../clean_data/Digitale_Tweelingstad_Zwolle_Adressen_2D_cleaned.shp\n",
      "‚úÖ Selected columns saved to: ../minimized_data/Digitale_Tweelingstad_Zwolle_Selected_minimized.shp\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "CLEAN_DATA_DIR = \"../clean_data/\"\n",
    "OUTPUT_DIR = \"../minimized_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "shapefile_path = os.path.join(CLEAN_DATA_DIR, \"Digitale_Tweelingstad_Zwolle_Adressen_2D_cleaned.shp\")\n",
    "output_shapefile_path = os.path.join(OUTPUT_DIR, \"Digitale_Tweelingstad_Zwolle_Selected_minimized.shp\")\n",
    "\n",
    "# Variables to select\n",
    "selected_columns = [\"status\", \"bouwjaar\", \"buurt_naam\", \"wijk_naam\", \"energielab\", \"geometry\", \"adres\"]\n",
    "\n",
    "# -------------------------------\n",
    "# PROCESSING SHAPEFILE\n",
    "# -------------------------------\n",
    "print(f\"\\nüîÑ Processing shapefile: {shapefile_path}\")\n",
    "try:\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    \n",
    "    # Check for missing columns\n",
    "    missing_columns = set(selected_columns) - set(gdf.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in the shapefile: {missing_columns}\")\n",
    "\n",
    "    # Select specified columns\n",
    "    gdf_selected = gdf[selected_columns]\n",
    "\n",
    "    # Save to new shapefile\n",
    "    gdf_selected.to_file(output_shapefile_path)\n",
    "    print(f\"‚úÖ Selected columns saved to: {output_shapefile_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to process shapefile: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation based on neighbourhood\n",
    "\n",
    "The following code perform aggregation of values included in specific columns per neighborhood based on file Digitale_Tweelingstad_Zwolle_Adressen_2D_cleaned.shp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aggregated shapefile saved successfully to: ../aggregated_data/Zwolle_Neighborhood_Aggregated_Buildings.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_21836\\3921137456.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  agg_df = gdf.groupby(\"buurt_naam\").apply(lambda df: pd.Series({\n",
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_21836\\3921137456.py:64: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  final_gdf.to_file(output_path)\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'total_buildings' to 'total_buil'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'occupied_pct' to 'occupied_p'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'unoccupied_pct' to 'unoccupied'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'high_efficiency' to 'high_effic'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'moderate_efficiency' to 'moderate_e'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'low_efficiency' to 'low_effici'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'unknown_efficiency' to 'unknown_ef'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration paths\n",
    "MINIMIZED_DATA_DIR = \"../minimized_data/\"\n",
    "OUTPUT_DIR = \"../aggregated_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load minimized shapefile\n",
    "gdf = gpd.read_file(os.path.join(MINIMIZED_DATA_DIR, \"Digitale_Tweelingstad_Zwolle_Selected_minimized.shp\"))\n",
    "\n",
    "# Drop rows with missing crucial data\n",
    "gdf = gdf.dropna(subset=[\"bouwjaar\", \"energielab\", \"status\", \"buurt_naam\", \"geometry\"])\n",
    "\n",
    "# Create building age categories\n",
    "bins = [0, 1945, 1960, 1980, 2000, 2010, 2025]\n",
    "labels = [\"Pre-1945\", \"1945-1960\", \"1961-1980\", \"1981-2000\", \"2001-2010\", \"2011-2025\"]\n",
    "gdf[\"bouwjaar_cat\"] = pd.cut(gdf[\"bouwjaar\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Simplify occupancy status\n",
    "gdf[\"occupied\"] = gdf[\"status\"].apply(lambda x: \"occupied\" if \"in gebruik\" in x.lower() else \"unoccupied\")\n",
    "\n",
    "# Categorize energy labels\n",
    "def categorize_energy_label(label):\n",
    "    high_efficiency = ['A++', 'A+', 'A']\n",
    "    moderate_efficiency = ['B', 'C', 'D']\n",
    "    low_efficiency = ['E', 'F', 'G']\n",
    "\n",
    "    if label in high_efficiency:\n",
    "        return 'high_efficiency'\n",
    "    elif label in moderate_efficiency:\n",
    "        return 'moderate_efficiency'\n",
    "    elif label in low_efficiency:\n",
    "        return 'low_efficiency'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "gdf[\"energy_category\"] = gdf[\"energielab\"].apply(categorize_energy_label)\n",
    "\n",
    "# Aggregate data at neighborhood level\n",
    "agg_df = gdf.groupby(\"buurt_naam\").apply(lambda df: pd.Series({\n",
    "    \"total_buildings\": len(df),\n",
    "    \"occupied_pct\": (df[\"occupied\"] == \"occupied\").mean() * 100,\n",
    "    \"unoccupied_pct\": (df[\"occupied\"] == \"unoccupied\").mean() * 100,\n",
    "    \"pre_1945\": (df[\"bouwjaar_cat\"] == \"Pre-1945\").sum(),\n",
    "    \"1945_1960\": (df[\"bouwjaar_cat\"] == \"1945-1960\").sum(),\n",
    "    \"1961_1980\": (df[\"bouwjaar_cat\"] == \"1961-1980\").sum(),\n",
    "    \"1981_2000\": (df[\"bouwjaar_cat\"] == \"1981-2000\").sum(),\n",
    "    \"2001_2010\": (df[\"bouwjaar_cat\"] == \"2001-2010\").sum(),\n",
    "    \"2011_2024\": (df[\"bouwjaar_cat\"] == \"2011-2024\").sum(),\n",
    "    \"high_efficiency\": (df[\"energy_category\"] == \"high_efficiency\").sum(),\n",
    "    \"moderate_efficiency\": (df[\"energy_category\"] == \"moderate_efficiency\").sum(),\n",
    "    \"low_efficiency\": (df[\"energy_category\"] == \"low_efficiency\").sum(),\n",
    "    \"unknown_efficiency\": (df[\"energy_category\"] == \"unknown\").sum(),\n",
    "})).reset_index()\n",
    "\n",
    "# Merge aggregated data with geometry\n",
    "geometry_df = gdf.dissolve(by=\"buurt_naam\").geometry.reset_index()\n",
    "final_gdf = geometry_df.merge(agg_df, on=\"buurt_naam\")\n",
    "\n",
    "# Save aggregated data to shapefile\n",
    "output_path = os.path.join(OUTPUT_DIR, \"Zwolle_Neighborhood_Aggregated_Buildings.shp\")\n",
    "final_gdf.to_file(output_path)\n",
    "\n",
    "print(f\"‚úÖ Aggregated shapefile saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation based on district\n",
    "\n",
    "The following code perform aggregation of values included in specific columns per district based on file Digitale_Tweelingstad_Zwolle_Adressen_2D_cleaned.shp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aggregated shapefile saved successfully to: ../aggregated_data/Zwolle_District_Aggregated_Buildings.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_21836\\1022747079.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  agg_df = gdf.groupby(\"wijk_naam\").apply(lambda df: pd.Series({\n",
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_21836\\1022747079.py:64: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  final_gdf.to_file(output_path)\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'total_buildings' to 'total_buil'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'occupied_pct' to 'occupied_p'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'unoccupied_pct' to 'unoccupied'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'high_efficiency' to 'high_effic'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'moderate_efficiency' to 'moderate_e'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'low_efficiency' to 'low_effici'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'unknown_efficiency' to 'unknown_ef'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Configuration paths\n",
    "MINIMIZED_DATA_DIR = \"../minimized_data/\"\n",
    "OUTPUT_DIR = \"../aggregated_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load minimized shapefile\n",
    "gdf = gpd.read_file(os.path.join(MINIMIZED_DATA_DIR, \"Digitale_Tweelingstad_Zwolle_Selected_minimized.shp\"))\n",
    "\n",
    "# Drop rows with missing crucial data\n",
    "gdf = gdf.dropna(subset=[\"bouwjaar\", \"energielab\", \"status\", \"wijk_naam\", \"geometry\"])\n",
    "\n",
    "# Create building age categories\n",
    "bins = [0, 1945, 1960, 1980, 2000, 2010, 2024]\n",
    "labels = [\"Pre-1945\", \"1945-1960\", \"1961-1980\", \"1981-2000\", \"2001-2010\", \"2011-2024\"]\n",
    "gdf[\"bouwjaar_cat\"] = pd.cut(gdf[\"bouwjaar\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# Simplify occupancy status\n",
    "gdf[\"occupied\"] = gdf[\"status\"].apply(lambda x: \"occupied\" if \"in gebruik\" in x.lower() else \"unoccupied\")\n",
    "\n",
    "# Categorize energy labels\n",
    "def categorize_energy_label(label):\n",
    "    high_efficiency = ['A++', 'A+', 'A']\n",
    "    moderate_efficiency = ['B', 'C', 'D']\n",
    "    low_efficiency = ['E', 'F', 'G']\n",
    "\n",
    "    if label in high_efficiency:\n",
    "        return 'high_efficiency'\n",
    "    elif label in moderate_efficiency:\n",
    "        return 'moderate_efficiency'\n",
    "    elif label in low_efficiency:\n",
    "        return 'low_efficiency'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "gdf[\"energy_category\"] = gdf[\"energielab\"].apply(categorize_energy_label)\n",
    "\n",
    "# Aggregate data at district level\n",
    "agg_df = gdf.groupby(\"wijk_naam\").apply(lambda df: pd.Series({\n",
    "    \"total_buildings\": len(df),\n",
    "    \"occupied_pct\": (df[\"occupied\"] == \"occupied\").mean() * 100,\n",
    "    \"unoccupied_pct\": (df[\"occupied\"] == \"unoccupied\").mean() * 100,\n",
    "    \"pre_1945\": (df[\"bouwjaar_cat\"] == \"Pre-1945\").sum(),\n",
    "    \"1945_1960\": (df[\"bouwjaar_cat\"] == \"1945-1960\").sum(),\n",
    "    \"1961_1980\": (df[\"bouwjaar_cat\"] == \"1961-1980\").sum(),\n",
    "    \"1981_2000\": (df[\"bouwjaar_cat\"] == \"1981-2000\").sum(),\n",
    "    \"2001_2010\": (df[\"bouwjaar_cat\"] == \"2001-2010\").sum(),\n",
    "    \"2011_2024\": (df[\"bouwjaar_cat\"] == \"2011-2024\").sum(),\n",
    "    \"high_efficiency\": (df[\"energy_category\"] == \"high_efficiency\").sum(),\n",
    "    \"moderate_efficiency\": (df[\"energy_category\"] == \"moderate_efficiency\").sum(),\n",
    "    \"low_efficiency\": (df[\"energy_category\"] == \"low_efficiency\").sum(),\n",
    "    \"unknown_efficiency\": (df[\"energy_category\"] == \"unknown\").sum(),\n",
    "})).reset_index()\n",
    "\n",
    "# Merge aggregated data with geometry\n",
    "geometry_df = gdf.dissolve(by=\"wijk_naam\").geometry.reset_index()\n",
    "final_gdf = geometry_df.merge(agg_df, on=\"wijk_naam\")\n",
    "\n",
    "# Save aggregated data to shapefile\n",
    "output_path = os.path.join(OUTPUT_DIR, \"Zwolle_District_Aggregated_Buildings.shp\")\n",
    "final_gdf.to_file(output_path)\n",
    "\n",
    "print(f\"‚úÖ Aggregated shapefile saved successfully to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
