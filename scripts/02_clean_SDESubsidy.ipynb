{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a350eb-f261-4b9c-809d-ae3c6f64d377",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean SDE Subsidy Data\n",
    "This script cleans subsidy data downloaded from RVO.nl and compiled in Excel on SDE and SDE+++ subsidies by removing all records that do not have latitude and longitude.\n",
    "\n",
    "\n",
    "About the raw data:\n",
    "\n",
    "The subsidy data from RVO.nl was originally download as XLSX files. Upon initial inspection, it was noted that the files contained extra informational columns and rows that needed to be deleted. The information included images and plain text introduction material. The following columns remain:\n",
    " - OBJECTID\n",
    " - Programma\n",
    " - Projectnummer\n",
    " - Adres\n",
    " - Postal Code\n",
    " - Indienronde\n",
    " - Realisatiejaar\n",
    " - Kwartaal\n",
    " - Aavrager\n",
    " - Status\n",
    " - Vermogen\n",
    " - Maximale_subsidie\n",
    " - Looptijd\n",
    " - Rechtsvorm\n",
    " - Provincie\n",
    " - Latitude\n",
    " - Longitude\n",
    " - Categorie\n",
    " - Thema\n",
    " - label\n",
    " - RES_regio\n",
    " - Gemeente\n",
    " - Plaats\n",
    " - x\n",
    " - y\n",
    "\n",
    "\n",
    "Processing and output:\n",
    "\n",
    "The file was saved as a CSV and used in the script below. The final output is generates a CSV file.\n",
    "\n",
    "## Before running:\n",
    "1. Update directories and file names as necessary under CONFIGURATION\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1409e911-07d7-4628-8dad-67c6b4c6f2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Programma types found:\n",
      " programma\n",
      "SDE    131\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Total rows after full cleaning and validation: 131\n",
      "üìÅ Cleaned file saved to: ../clean_data/sde_subsidies_clean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_28224\\2723776948.py:27: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "RAW_DATA_DIR = \"../raw_data/\"\n",
    "OUTPUT_DIR = \"../clean_data/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "input_file = os.path.join(RAW_DATA_DIR, \"SDE.csv\")\n",
    "output_file = os.path.join(OUTPUT_DIR, \"sde_subsidies_clean.csv\")\n",
    "\n",
    "# -------------------------------\n",
    "# FUNCTIONS\n",
    "# -------------------------------\n",
    "def clean_column_names(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\", regex=False)\n",
    "        .str.replace(\".\", \"_\", regex=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def strip_whitespace(df):\n",
    "    return df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "def clean_data(df):\n",
    "    df = clean_column_names(df)\n",
    "    df = strip_whitespace(df)\n",
    "    df = df.dropna(how='all')  # Drop entirely empty rows\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def remove_missing_coordinates(df):\n",
    "    if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "        df = df.dropna(subset=['latitude', 'longitude'])\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Columns 'latitude' and/or 'longitude' not found in the dataset.\")\n",
    "    return df\n",
    "\n",
    "def validate_and_clean_columns(df):\n",
    "    # projectnummer as string\n",
    "    if 'projectnummer' in df.columns:\n",
    "        df['projectnummer'] = df['projectnummer'].astype(str)\n",
    "\n",
    "    # programma: drop blanks, count types\n",
    "    if 'programma' in df.columns:\n",
    "        df = df[df['programma'].notna() & (df['programma'] != \"\")]\n",
    "        programma_counts = df['programma'].value_counts()\n",
    "        print(\"üìä Programma types found:\\n\", programma_counts)\n",
    "\n",
    "    # maximal_subsidie: convert to int euros (remove decimal)\n",
    "    if 'maximal_subsidie' in df.columns:\n",
    "        df['maximal_subsidie'] = (\n",
    "            df['maximal_subsidie']\n",
    "            .replace(\",\", \".\", regex=True)\n",
    "            .astype(float)\n",
    "            .round(0)\n",
    "            .astype('Int64')\n",
    "        )\n",
    "\n",
    "    # realisatiejaar: ensure it's a valid year, no blanks\n",
    "    if 'realisatiejaar' in df.columns:\n",
    "        df = df[df['realisatiejaar'].notna()]\n",
    "        df['realisatiejaar'] = df['realisatiejaar'].astype(str).str.extract(r'(\\d{4})')[0]\n",
    "        df = df[df['realisatiejaar'].notna()]\n",
    "        df['realisatiejaar'] = df['realisatiejaar'].astype(int)\n",
    "\n",
    "    # catagorie: make sure it's string\n",
    "    if 'catagorie' in df.columns:\n",
    "        df['catagorie'] = df['catagorie'].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# PROCESSING\n",
    "# -------------------------------\n",
    "df = pd.read_csv(input_file, sep=\",\")\n",
    "df = clean_data(df)\n",
    "df = remove_missing_coordinates(df)\n",
    "df = validate_and_clean_columns(df)\n",
    "\n",
    "# -------------------------------\n",
    "# SUMMARY\n",
    "# -------------------------------\n",
    "print(f\"‚úÖ Total rows after full cleaning and validation: {len(df)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# SAVE OUTPUT\n",
    "# -------------------------------\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"üìÅ Cleaned file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca75f0e-c552-4088-99fc-17634cd23014",
   "metadata": {},
   "source": [
    "## Minimize SDE Data\n",
    "The following code saves a minimized csv file with the following columns:\n",
    "    - projectnummer\n",
    "    - programma\n",
    "    - maximal_subsidie\n",
    "    - realisatiejaar\n",
    "    - catagorie\n",
    "    - latitude\n",
    "    - longitude\n",
    "\n",
    "## Before running:\n",
    "1. Update directories and file names as necessary under CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "896fc1d6-3f4f-42a2-a212-bd4b8974bfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Minimized file saved to both:\n",
      "üìÅ ../minimized_data/\n",
      "üìÅ ../geocoded_data/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------\n",
    "CLEANED_FILE = \"../clean_data/sde_subsidies_clean.csv\"\n",
    "MINIMIZED_DIR = \"../minimized_data/\"\n",
    "GEOCODED_DIR = \"../geocoded_data/\"\n",
    "OUTPUT_FILENAME = \"sde_minimized_geocoded.csv\"\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(MINIMIZED_DIR, exist_ok=True)\n",
    "os.makedirs(GEOCODED_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------------\n",
    "# COLUMNS TO KEEP\n",
    "# -------------------------------\n",
    "COLUMNS_TO_KEEP = [\n",
    "    \"projectnummer\",\n",
    "    \"programma\",\n",
    "    \"realisatiejaar\",\n",
    "    \"categorie\",\n",
    "    \"maximale_subsidie\",\n",
    "    \"latitude\",\n",
    "    \"longitude\"\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# LOAD & FILTER\n",
    "# -------------------------------\n",
    "df = pd.read_csv(CLEANED_FILE)\n",
    "\n",
    "# Ensure all required columns exist\n",
    "missing_cols = [col for col in COLUMNS_TO_KEEP if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"‚ùå Missing columns in input file: {missing_cols}\")\n",
    "\n",
    "# Filter only the needed columns\n",
    "df_minimized = df[COLUMNS_TO_KEEP]\n",
    "\n",
    "# -------------------------------\n",
    "# SAVE OUTPUTS\n",
    "# -------------------------------\n",
    "df_minimized.to_csv(os.path.join(MINIMIZED_DIR, OUTPUT_FILENAME), index=False)\n",
    "df_minimized.to_csv(os.path.join(GEOCODED_DIR, OUTPUT_FILENAME), index=False)\n",
    "\n",
    "print(f\"‚úÖ Minimized file saved to both:\\nüìÅ {MINIMIZED_DIR}\\nüìÅ {GEOCODED_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac2864a",
   "metadata": {},
   "source": [
    "# Aggregation based on neighbourhood\n",
    "\n",
    "This code aggregates subsidies occurence by performing a spatial join between geocoded subsidies data (sde_minimized_geocoded.csv) and neighborhood boundaries (Buurtgrenzen_Zwolle.shp). It calculates the total number of applied subsidies within each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "904a664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aggregated shapefile saved successfully to: ../aggregated_data/Zwolle_Neighbourhood_Aggregated_SDESubsidy.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_28224\\147011612.py:45: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  result_gdf.to_file(output_path)\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'subsidy_count' to 'subsidy_co'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'total_subsidy_amount' to 'total_subs'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "GEOCODED_DATA_DIR = \"../geocoded_data/\"\n",
    "NEIGHBORHOOD_DATA_DIR = \"../raw_data/\"\n",
    "OUTPUT_DIR = \"../aggregated_data/\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define paths explicitly\n",
    "input_file = os.path.join(GEOCODED_DATA_DIR, \"sde_minimized_geocoded.csv\")\n",
    "neighborhood_file = os.path.join(NEIGHBORHOOD_DATA_DIR, \"Buurtgrenzen_Zwolle.shp\")\n",
    "\n",
    "# Load SDE subsidy data and convert to GeoDataFrame\n",
    "subsidy_df = pd.read_csv(input_file)\n",
    "subsidy_gdf = gpd.GeoDataFrame(\n",
    "    subsidy_df,\n",
    "    geometry=gpd.points_from_xy(subsidy_df.longitude, subsidy_df.latitude),\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Load neighborhoods shapefile with correct CRS (EPSG:28992)\n",
    "neighborhoods_gdf = gpd.read_file(neighborhood_file)\n",
    "\n",
    "# Convert subsidy points to match neighborhoods CRS (EPSG:28992)\n",
    "subsidy_gdf = subsidy_gdf.to_crs(neighborhoods_gdf.crs)\n",
    "\n",
    "# Spatial join: assign subsidies to neighborhoods\n",
    "joined_gdf = gpd.sjoin(subsidy_gdf, neighborhoods_gdf, predicate='within')\n",
    "\n",
    "# Count subsidies and sum subsidy amounts per neighborhood\n",
    "aggregated_subsidies = joined_gdf.groupby('OFFICI√ãLE').agg(\n",
    "    subsidy_count=('maximale_subsidie', 'size'),\n",
    "    total_subsidy_amount=('maximale_subsidie', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Merge aggregation results back with neighborhood geometry\n",
    "result_gdf = neighborhoods_gdf.merge(aggregated_subsidies, on='OFFICI√ãLE', how='left')\n",
    "result_gdf['subsidy_count'] = result_gdf['subsidy_count'].fillna(0).astype(int)\n",
    "result_gdf['total_subsidy_amount'] = result_gdf['total_subsidy_amount'].fillna(0)\n",
    "\n",
    "# Save aggregated data to shapefile\n",
    "output_path = os.path.join(OUTPUT_DIR, \"Zwolle_Neighbourhood_Aggregated_SDESubsidy.shp\")\n",
    "result_gdf.to_file(output_path)\n",
    "\n",
    "print(f\"‚úÖ Aggregated shapefile saved successfully to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec60f8",
   "metadata": {},
   "source": [
    "# Aggregation based on district\n",
    "\n",
    "This code aggregates subsidies occurence by performing a spatial join between geocoded subsidies data (sde_minimized_geocoded.csv) and district boundaries (Wijkgrenzen_Zwolle.shp). It calculates the total number of applied subsidies within each district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b20f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Aggregated shapefile saved successfully to: ../aggregated_data/Zwolle_Districts_Aggregated_SDESubsidy.shp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kemun\\AppData\\Local\\Temp\\ipykernel_28224\\3394971484.py:45: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  result_gdf.to_file(output_path)\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'subsidy_count' to 'subsidy_co'\n",
      "  ogr_write(\n",
      "c:\\Users\\kemun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:723: RuntimeWarning: Normalized/laundered field name: 'total_subsidy_amount' to 'total_subs'\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "GEOCODED_DATA_DIR = \"../geocoded_data/\"\n",
    "DISTRICT_DATA_DIR = \"../raw_data/\"\n",
    "OUTPUT_DIR = \"../aggregated_data/\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define paths explicitly\n",
    "input_file = os.path.join(GEOCODED_DATA_DIR, \"sde_minimized_geocoded.csv\")\n",
    "district_file = os.path.join(DISTRICT_DATA_DIR, \"Wijkgrenzen_Zwolle.shp\")\n",
    "\n",
    "# Load SDE subsidy data and convert to GeoDataFrame\n",
    "subsidy_df = pd.read_csv(input_file)\n",
    "subsidy_gdf = gpd.GeoDataFrame(\n",
    "    subsidy_df,\n",
    "    geometry=gpd.points_from_xy(subsidy_df.longitude, subsidy_df.latitude),\n",
    "    crs='EPSG:4326'\n",
    ")\n",
    "\n",
    "# Load districts shapefile with correct CRS (EPSG:28992)\n",
    "districts_gdf = gpd.read_file(district_file)\n",
    "\n",
    "# Convert subsidy points to match districts CRS (EPSG:28992)\n",
    "subsidy_gdf = subsidy_gdf.to_crs(districts_gdf.crs)\n",
    "\n",
    "# Spatial join: assign subsidies to districts\n",
    "joined_gdf = gpd.sjoin(subsidy_gdf, districts_gdf, predicate='within')\n",
    "\n",
    "# Count subsidies and sum subsidy amounts per district\n",
    "aggregated_subsidies = joined_gdf.groupby('OFFICI√ãLE').agg(\n",
    "    subsidy_count=('maximale_subsidie', 'size'),\n",
    "    total_subsidy_amount=('maximale_subsidie', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# Merge aggregation results back with district geometry\n",
    "result_gdf = districts_gdf.merge(aggregated_subsidies, on='OFFICI√ãLE', how='left')\n",
    "result_gdf['subsidy_count'] = result_gdf['subsidy_count'].fillna(0).astype(int)\n",
    "result_gdf['total_subsidy_amount'] = result_gdf['total_subsidy_amount'].fillna(0)\n",
    "\n",
    "# Save aggregated data to shapefile\n",
    "output_path = os.path.join(OUTPUT_DIR, \"Zwolle_Districts_Aggregated_SDESubsidy.shp\")\n",
    "result_gdf.to_file(output_path)\n",
    "\n",
    "print(f\"‚úÖ Aggregated shapefile saved successfully to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
